---
layout: post
title:  "Google JAX 라이브러리란?"
summary: "Google JAX 라이브러리란?"
date:   2021-05-22 09:10 -0400
categories: library
---

# JAX

- Github : [https://github.com/google/jax](https://github.com/google/jax)
- Docs : [https://jax.readthedocs.io/en/latest/](https://jax.readthedocs.io/en/latest/)

요즘 Deep Learning 오픈소스를 보면 JAX를 사용한 많은 프로젝트가 보인다. 실제 DeepMind도 자신들의 프로젝트의 대부분을 "JAX"와 결합을 시켰다고 하는데.. 왜이렇게 인기가 많을까?

JAX는 Google이 만든 Python과 Numpy만을 결합한 머신러닝 라이브러리다. 간단하게 요약하면

- ONLY NUMPY : Numpy를 GPU에서 연산시킬 수 있게 하여 기존 Numpy 성능을 뛰어넘는다. (깃허브를 보면 90% 이상의 코드가 파이썬이다.)
- 자동 미분 계산
- jit(just in time) 컴파일 기법과 XLA 컴파일러를 사용하여 컴파일을 할 수 있다. (XLA는 모든 기기에 적용될 예정이라고 합니다.)

라이브러리 API

- `grad`, `jit` : instances of such transformations.
- `vmap` : automatic vectorization
- `pmap` : single-program multiple-data (SPMD) parallel programming of multiple accelerators, with more to come.

확실히 Python과 Numpy만으로(+ GPU) 개발되었다는 점이 놀랍다. 이는 tensor array와 같은 것을 고려하지 않고 numpy array만을 고려해서 코드를 짤 수 있다는 것인데 이 부분이 가장 큰 장점이지 않을까 생각된다.

그리고 jit 컴파일 데코레이터 함수를 적용하면 부분 컴파일이 가능해 깔끔하게 작성된 코드에서는 큰 장점을 가진다고 한다.

컴파일의 개념이 Pytorch같은 라이브러리에도 적용될 가능성이 있지 않을까 생각된다.

## 튜토리얼
